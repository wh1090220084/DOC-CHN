​
一、准备
1、硬件
准备一台至少12核CPU、24G内存、1T硬盘（最好SSD）和一个不低于10MB能上互联网的网络。（最好能满足上面的条件，要不然即使安装的没有问题，也可能跑不起来）。

2    软件
Xshell 、VMware Workstation 16 Pro，这两款软件的下载地址： https://pan.baidu.com/s/1j6j4n4TMlxxvtSFb-r_G5A  提取码：52bv

Centos，下载地址：

http://vault.centos.org/7.5.1804/isos/x86_64/CentOS-7-x86_64-DVD-1804.iso

二、安装 VMWare虚拟机安装
从我给的网盘地址将VMWare软件下载下来安装即可，自行激活，如果有问题问度娘。

安装完成后，点击“编辑→虚拟网络编辑器”，如下图：



查找网关



选择VMnet8，然后点击NAT设置。



在这里找到网关：192.168.65.2 记住这个网关，后面配置网络的时候要用到。

三、CentOS安装
打开vwmare软件，点击创建新的虚拟机



选择“典型（推荐）“，然后选择”下一步“。



选择“下一步“



如下图，选择“Linux“、”Centos7 64位“、然后选择”下一步“



给虚拟机命名，第一台命名为“fate01”,第二台虚拟机命名为“fate02”。

然后选择安装路径，安装在空间较大的盘符。然后选择“下一步”



最大磁盘大小设置为“500G”，选择“将磁盘拆分成多个文件”，然后选择“下一步”.



选择“自定义硬件”，如下图：



然后设置内存为8G，处理器数量设置为1，每个处理器的内核数量设置为4，在“新CD/DCD(IDE)”选项中设置“CentOS-7-x86_64-DVD-1804.iso”文件的路径，完成上面的设置后选择关闭。



 

然后我们就能看到虚拟机的配置，如果没有问题，则选择”完成”，等待虚拟机安装结束。



出现下图则说明安装完成，选择“开启此虚拟机”，你就可以看到Centos7的安装页面。



选择“Install CentOS 7”，然后按“Enter”键。



出下面如下画面，选择“中文”，在右侧选择“简体中文（中国）”，然后选择“继续”。



选择“键盘”，点击“+”，选择“英语（英国）”，然后点击“添加”，再选择“完成”。





 

接下来，点击“软件选择”。在左侧选择“最小安装”，在右侧选择“调试工具”和”系统管理工具”。然后选择“完成”。

 

 

设置“安装位置”，然后选择“我要配置分区”，选择“完成”。





然后出现如下画面，选择“点这里自动创建他们”



选择“home”，设置期望容量为100GiB，然后点击“+”



添加新的挂载点“/data”,容量为“341.12GiB”，然后点击“添加挂载点”。



然后点击“完成”，选择“接受更改”



 

点击“网路和主机名”



以太网，选择“打开”，设置主机名为“fate01”，点击“应用”，然后选择“配置”。



点击“IPv4设置”，方法设置为“手动”，点击“Add”，增加IP地址，如下图，ip地址为“192.168.65.161”，另一台的ip地址设置为192.168.65.162，子网掩码和网关相同都，分别设置为“24”和“192.168.65.2”（这个网关我们在前面提到过）。DNS服务器设置为“192.168.65.2”，勾选“需要IPv4地址完成这个连接”。



点击”IPv6设置”，方法选择“忽略”。然后选择“保存”。



然后观察IP设置是否正确，如果没有问题则选择“完成”。



完成上面的设置后，选择“开始安装”。然后设置root密码。



将密码设置为“123456”，然后点击“完成”，等待安装完成。



安装完成后，点击“重启”。



重启之后，出现如下画面，输入“root”，密码“123456”登录root账户。



另一台虚拟机的安装步骤和第一台一样只是名字是“fate02”，IP地址为“192.168.65.162”。

安装完成后，安装Xshell，用Xshell登录。个人认为用xshell执行命令方便一些。

四、Fate AllinOne部署集群
1.集群规划
party

主机名

IP地址

操作系统

安装软件

服务

PartyA

VM_0_1_centos

192.168.65.161

CentOS 7.2/

fate,eggroll,mysql

fate_flow，fateboard，clustermanager，nodemanager，rollsite，mysql

PartyB

VM_0_2_centos

192.168.65.162

CentOS 7.2

fate,eggroll,mysql

fate_flow，fateboard，clustermanager，nodemanager，rollsite，m

2.架构图


3.组件说明
软件产品

组件

端口

说明

fate

fate_flow

9360;9380

联合学习任务流水线管理模块

fate

fateboard

8080

联合学习过程可视化模块

eggroll

clustermanager

4670

cluster manager管理集群

eggroll

nodemanager

4671

node manager管理每台机器资源

eggroll

rollsite

9370

跨站点或者说跨party通讯组件，相当于以前版本的proxy+federation

mysql

mysql

3306

数据存储，clustermanager和fateflow依赖

4、环境配置
4.1 hostname配置
 1）修改主机名

在192.168.65.161 root用户下执行：

hostnamectl set-hostname VM_0_1_centos

在192.168.65.162 root用户下执行：

hostnamectl set-hostname VM_0_2_centos

  2）加入主机映射

在目标服务器（192.168.65.161 192.168.65.162）root用户下执行：

vi /etc/hosts
添加内容

192.168.0.1 VM_0_1_centos
192.168.0.2 VM_0_2_centos


添加完成后，执行"su root"命令重新登录。

4.2 关闭selinux

在目标服务器（192.168.65.161 192.168.65.162）root用户下执行：

确认是否已安装selinux

centos系统执行：rpm -qa | grep selinux

ubuntu系统执行：apt list --installed | grep selinux

如果已安装了selinux就执行：setenforce 0



4.3 配置yum仓库
 在目标服务器（192.168.65.161 192.168.65.162）root用户下执行：

1）备份CentOS-Base.repo文件

mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak


2）修改yum仓库配置

vi /etc/yum.repos.d/CentOS-Base.repo
添加内容： 

# CentOS-Base.repo
#
# The mirror system uses the connecting IP address of the client and the
# update status of each mirror to pick mirrors that are updated to and
# geographically close to the client.  You should use this for CentOS updates
# unless you are manually picking other mirrors.
#
# If the mirrorlist= does not work for you, as a fall back you can try the
# remarked out baseurl= line instead.
#
#

[base]
name=CentOS-$releasever - Base
baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/os/$basearch/
#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=os
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7

#released updates
[updates]
name=CentOS-$releasever - Updates
baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/updates/$basearch/
#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=updates
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7

#additional packages that may be useful
[extras]
name=CentOS-$releasever - Extras
baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/extras/$basearch/
#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=extras
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7

#additional packages that extend functionality of existing packages
[centosplus]
name=CentOS-$releasever - Plus
baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos/$releasever/centosplus/$basearch/
#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=centosplus
gpgcheck=1
enabled=0
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7
3）使新仓库配置生效

yum clean all
yum makecache
 

4.4 修改Linux系统参数
在目标服务器（192.168.65.161 192.168.65.162）root用户下执行：

1）清理20-nproc.conf文件

cd /etc/security/limits.d
ls -lrt 20-nproc.conf
存在则：

mv 20-nproc.conf 20-nproc.conf_bak


2）修改limits.conf文件

vi /etc/security/limits.conf
 添加下面的信息：

* soft nofile 65535
* hard nofile 65535
* soft nproc 65535
* hard nproc 65535


 重新登陆，ulimit -a查看是否生效

 

 4.5 修改系统mysql配置
mv /etc/my.cnf /etc/my.cnf_bak



4.6 关闭防火墙(可选)
在目标服务器（192.168.65.161 192.168.65.162）root用户下执行

systemctl disable firewalld.service
systemctl stop firewalld.service
systemctl status firewalld.service


4.7 创建APP用户
在目标服务器（192.168.65.161 192.168.65.162）root用户下执行

groupadd -g 6000 apps
useradd -s /bin/bash -g apps -d /home/app app
passwd app

app初识密码设置为123456



4.8  给APP用户配置sudo
 在目标服务器（192.168.65.161 192.168.65.162）root用户下执行

vi /etc/sudoers.d/app
添加内容： 

app ALL=(ALL) ALL
app ALL=(ALL) NOPASSWD: ALL
Defaults !env_reset


给文件sudoers文件增加写入权限

chmod u+w /etc/sudoers
编辑 sudoers文件

vi /etc/sudoers
在root    ALL=(ALL)       ALL下面追加：

root    ALL=(ALL)       NOPASSWD: ALL
app     ALL=(ALL)       ALL
app     ALL=(ALL)       NOPASSWD: ALL
 给文件sudoers文件删除写入权限

chmod u-w /etc/sudoers
 

4.9 增加虚拟内存
 在目标服务器（192.168.65.161 192.168.65.162）root用户下执行

生产环境使用时，因内存计算需要增加128G虚拟内存，执行前需检查存储空间是否足够。

手工创建，root用户执行：

cd /data
dd if=/dev/zero of=/data/swapfile128G bs=1024 count=134217728
mkswap /data/swapfile128G
swapon /data/swapfile128G
cat /proc/swaps
echo '/data/swapfile128G swap swap defaults 0 0' >> /etc/fstab


4.10  设置projects目录
 在目标服务器（192.168.65.161 192.168.65.162）root用户下执行

cd /data
mkdir projects
chown app:apps projects
ls -l
chown -R app /data


4.11 配置ssh无密登录
1）配置自身免密

在目标服务器（192.168.65.161 192.168.65.162）app用户下执行

在虚拟机VM_0_1_centos 上以app用户身份在home目录下执行

su app
ssh-keygen -t rsa
cat ~/.ssh/id_rsa.pub >>/home/app/.ssh/authorized_keys
chmod 600 ~/.ssh/authorized_keys


 使用ssh 192.168.65.161命令测试，第一次需要确认yes ,之后应可以不需密码登录为成功。



 在VM_0_2_centos 上执行相同步骤配置VM_0_2_centos 的自身免密登录。

2）配置VM_0_1_centos 免密登录VM_0_2_centos

在VM_0_1_centos  app用户下执行

scp ~/.ssh/authorized_keys app@192.168.65.162:/home/app/.ssh
输入VM_0_2_centos的app密码

在VM_0_2_centos app用户下执行

cat ~/.ssh/id_rsa.pub >> /home/app/.ssh/authorized_keys

scp ~/.ssh/authorized_keys app@192.168.65.161:/home/app/.ssh
输入VM_0_1_centos 的app密码完成文件传输。 

在VM_0_1_centos app用户下执行

ssh 192.168.65.162
应不需要密码即可登录fate02机。

到这里我们已经完成环境的配置了。

五.项目部署
5.1 获取项目
在目标服务器（192.168.65.161 具备外网环境）app用户下执行

进入执行节点的/data/projects/目录，执行：

cd /data/projects/
wget https://webank-ai-1251170195.cos.ap-guangzhou.myqcloud.com/fate_cluster_install_1.6.0_release-c7-u18.tar.gz
tar xzf fate_cluster_install_1.6.0_release-c7-u18.tar.gz
5.2 部署前检查
在目标服务器（192.168.65.161 192.168.65.162 ）app用户下执行

把检查脚本fate-cluster-install/tools-install/check.sh从192.168.65.161拷贝到192.168.65.162

#在192.168.0.1和192.168.0.2服务器上分别执行检查脚本
sh ./check.sh

#确认app用户已配置sudo
#虚拟内存，size不低于128G，如不满足需参考4.6章节重新设置
#文件句柄数，不低于65535，如不满足需参考4.3章节重新设置
#用户进程数，不低于64000，如不满足需参考4.3章节重新设置
#确认部署前没有fate进程和端口冲突
#确认/etc/my.cnf是否存在，存在需要mv；确认是否存在/data/projects/fate目录，存在需把fate目录mv备份。
5.3 配置文件修改和示例
在目标服务器（192.168.65.161）app用户下执行

修改配置文件fate-cluster-install/allInone/conf/setup.conf.

vi fate-cluster-install/allInone/conf/setup.conf
配置文件setup.conf说明：

配置项	配置项值	说明
roles	默认："host" "guest"	部署的角色，有HOST端、GUEST端
version	默认：1.5.1	Fate 版本号
pbase	默认： /data/projects	项目根目录
lbase	默认：/data/logs	保持默认不要修改
ssh_user	默认：app	ssh连接目标机器的用户，也是部署后文件的属主
ssh_group	默认：apps	ssh连接目标的用户的属组，也是部署后文件的属组
ssh_port	默认：22,根据实际情况修改	ssh连接端口，部署前确认好端口，不然会报连接错误
eggroll_dbname	默认：eggroll_meta	eggroll连接的DB名字
fate_flow_dbname	默认：fate_flow	fate_flow、fateboard等连接的DB名字
mysql_admin_pass	默认	mysql的管理员（root）密码
redis_pass	默认	redis密码，暂未使用
mysql_user	默认：fate	msyql的应用连接账号
mysql_port	默认：3306，根据实际情况修改	msql服务监听的端口
host_id	默认 : 10000，根据实施规划修改	HOST端的party id。
host_ip	192.168.0.1	HOST端的ip
host_mysql_ip	默认和host_ip保持一致	HOST端mysql的ip
host_mysql_pass	默认	HOST端msyql的应用连接账号
guest_id	默认 : 9999，根据实施规划修改	GUEST端的party id
guest_ip	192.168.0.2	GUEST端的ip
guest_mysql_ip	默认和guest_ip保持一致	GUEST端mysql的ip
guest_mysql_pass	默认	GUEST端msyql的应用连接账号
dbmodules	默认："mysql"	DB组件的部署模块列表，如mysql
basemodules	默认："tools" "base" "java" "python" "eggroll" "fate"	非DB组件的部署模块列表，如 "tools" "base"、 "java"、 "python" 、"eggroll" 、"fate"
fateflow_grpc_port	默认：9360	fateflow grpc服务端口
fateflow_http_port	默认：9380	fateflow http服务端口
fateboard_port	默认：8080	fateboard服务端口
rollsite_port	默认：9370	rollsite服务端口
clustermanager_port	默认：4670	clustermanager服务端口
nodemanager_port	默认：4671	nodemanager服务端口
1）两台主机partyA+partyB同时部署

#to install role
roles=( "host" "guest" )
​
version="1.6.0"
#project base
pbase="/data/projects"
#log directory
lbase="/data/logs"
​
#user who connects dest machine by ssh
ssh_user="app"
ssh_group="apps"
#ssh port
ssh_port=22
​
#eggroll_db name
eggroll_dbname="eggroll_meta"
#fate_flow_db name
fate_flow_dbname="fate_flow"
​
#mysql init root password
mysql_admin_pass="fate_dev"
​
#redis passwd
redis_pass=""
​
#mysql user
mysql_user="fate"
#mysql port
mysql_port="3306"
​
#host party id
host_id="10000"
#host ip
host_ip="192.168.65.161"
#host mysql ip
host_mysql_ip="${host_ip}"
host_mysql_pass="fate_deV2999"
​
#guest party id
guest_id="9999"
#guest ip
guest_ip="192.168.65.162"
#guest mysql ip
guest_mysql_ip="${guest_ip}"
guest_mysql_pass="fate_deV2999"
​
#db module lists
dbmodules=( "mysql" )
​
#base module lists
basemodules=( "tools" "base" "java" "python" "eggroll" "fate" )
​
fateflow_grpc_port=9360
fateflow_http_port=9380
fateboard_port=8080
​
rollsite_port=9370
clustermanager_port=4670
nodemanager_port=4671
2）只部署一个party

#to install role
roles=( "host" )
​
version="1.6.0"
#project base
pbase="/data/projects"
#log directory
lbase="/data/logs"
​
#user who connects dest machine by ssh
ssh_user="app"
ssh_group="apps"
#ssh port
ssh_port=22
​
#eggroll_db name
eggroll_dbname="eggroll_meta"
#fate_flow_db name
fate_flow_dbname="fate_flow"
​
#mysql init root password
mysql_admin_pass="fate_dev"
​
#redis passwd
redis_pass=""
​
#mysql user
mysql_user="fate"
#mysql port
mysql_port="3306"
​
#host party id
host_id="10000"
#host ip
host_ip="192.168.65.161"
#host mysql ip
host_mysql_ip="${host_ip}"
host_mysql_pass="fate_deV2999"
​
#guest party id
guest_id=""
#guest ip
guest_ip=""
#guest mysql ip
guest_mysql_ip="${guest_ip}"
guest_mysql_pass=""
​
#db module lists
dbmodules=( "mysql" )
​
#base module lists
basemodules=( "tools" "base" "java" "python" "eggroll" "fate" )
​
fateflow_grpc_port=9360
fateflow_http_port=9380
fateboard_port=8080
​
rollsite_port=9370
clustermanager_port=4670
nodemanager_port=4671
5.4 部署
 按照上述配置含义修改setup.conf文件对应的配置项后，然后在fate-cluster-install/allInone目录下执行部署脚本：

cd fate-cluster-install/allInone
nohup sh ./deploy.sh > logs/boot.log 2>&1 &
部署日志输出在fate-cluster-install/allInone/logs目录下,实时查看是否有报错：

tail -f ./logs/deploy.log （部署结束，查看一下即可）
tail -f ./logs/deploy-guest.log （实时打印GUEST端的部署情况）
tail -f ./logs/deploy-mysql-guest.log  （实时打印GUEST端mysql的部署情况）
tail -f ./logs/deploy-host.log    （实时打印HOST端的部署情况）
tail -f ./logs/deploy-mysql-host.log    （实时打印HOST端mysql的部署情况）
deploy.log出现以下内容说明安装完成 

init over
deploy guest mysql  172.16.132.190  over
deploy guest 172.16.132.190  over
deploy host mysql 172.16.132.189  over
deploy host 172.16.132.189  over
 

5.5 问题定位
1）eggroll日志

/data/projects/fate/eggroll/logs/eggroll/bootstrap.clustermanager.err

/data/projects/fate/eggroll/logs/eggroll/clustermanager.jvm.err.log

/data/projects/fate/eggroll/logs/eggroll/nodemanager.jvm.err.log

/data/projects/fate/eggroll/logs/eggroll/bootstrap.nodemanager.err

/data/projects/fate/eggroll/logs/eggroll/bootstrap.rollsite.err

/data/projects/fate/eggroll/logs/eggroll/rollsite.jvm.err.log

2）fateflow日志

/data/projects/fate/python/logs/fate_flow/

3）fateboard日志

/data/projects/fate/fateboard/logs

6.测试
6.1 Toy_example部署验证
此测试您需要设置3个参数：guest_partyid，host_partyid，work_mode。

6.1.1 单边测试
1）192.168.65.162上执行，guest_partyid和host_partyid都设为10000：

source /data/projects/fate/bin/init_env.sh
cd /data/projects/fate/examples/toy_example/
python run_toy_example.py 10000 10000 1
类似如下结果表示成功：

"2020-04-28 18:26:20,789 - secure_add_guest.py[line:126] - INFO: success to calculate secure_sum, it is 1999.9999999999998"


提示：如出现max cores per job is 1, please modify job parameters报错提示，需要修改当前目录下文件toy_example_conf.json中参数task_cores为1.

2）192.168.65.162上执行，guest_partyid和host_partyid都设为9999：

source /data/projects/fate/bin/init_env.sh
cd /data/projects/fate/examples/toy_example/
python run_toy_example.py 9999 9999 1

类似如下结果表示成功：

"2020-04-28 18:26:20,789 - secure_add_guest.py[line:126] - INFO: success to calculate secure_sum, it is 1999.9999999999998"

6.1.2 双边测试
选定9999为guest方，在192.168.65.162上执行：

source /data/projects/fate/bin/init_env.sh
cd /data/projects/fate/examples/toy_example/
python run_toy_example.py 9999 10000 1
类似如下结果表示成功：

"2020-04-28 18:26:20,789 - secure_add_guest.py[line:126] - INFO: success to calculate secure_sum, it is 1999.9999999999998"



6.2 最小化测试
6.2.1 上传预设数据：
分别在192.168.65.161和192.168.65.162上执行：

source /data/projects/fate/bin/init_env.sh
cd /data/projects/fate/examples/scripts/
python upload_default_data.py -m 1
6.2.2 快速模式：
请确保guest和host两方均已分别通过给定脚本上传了预设数据。

快速模式下，最小化测试脚本将使用一个相对较小的数据集，即包含了569条数据的breast数据集。

选定9999为guest方，在192.168.65.162上执行：

source /data/projects/fate/bin/init_env.sh
cd /data/projects/fate/examples/min_test_task/
#单边测试
python run_task.py -m 1 -gid 9999 -hid 9999 -aid 9999 -f fast
#双边测试
python run_task.py -m 1 -gid 9999 -hid 10000 -aid 10000 -f fast
其他一些可能有用的参数包括：

-f: 使用的文件类型. "fast" 代表 breast数据集, "normal" 代表 default credit 数据集.

--add_sbt: 如果被设置为1, 将在运行完lr以后，启动secureboost任务，设置为0则不启动secureboost任务，不设置此参数系统默认为1。

若数分钟后在结果中显示了“success”字样则表明该操作已经运行成功了。若出现“FAILED”或者程序卡住，则意味着测试失败。

6.2.3 正常模式：
只需在命令中将“fast”替换为“normal”，其余部分与快速模式相同。

6.3 Fateboard testing
Fateboard是一项Web服务。如果成功启动了fateboard服务，则可以通过访问 http://192.168.65.161:8080 和 http://192.168.65.162:8080 来查看任务信息，如果有防火墙需开通。





7.系统运维
7.1 服务管理
在目标服务器（192.168.65.161 192.168.65.162）app用户下执行

7.1.1 Eggroll服务管理
source /data/projects/fate/bin/init_env.sh
cd /data/projects/fate/eggroll

启动/关闭/查看/重启所有：

sh ./bin/eggroll.sh all start/stop/status/restart

启动/关闭/查看/重启单个模块(可选：clustermanager，nodemanager，rollsite)：

sh ./bin/eggroll.sh clustermanager start/stop/status/restart

7.1.2 Mysql服务管理
启动/关闭/查看/重启mysql服务

cd /data/projects/fate/common/mysql/mysql-8.0.13
sh ./service.sh start|stop|status|restart
7.1.3 Fate服务管理
1) 启动/关闭/查看/重启fate_flow服务

source /data/projects/fate/bin/init_env.sh
cd /data/projects/fate/python/fate_flow
sh service.sh start|stop|status|restart

如果逐个模块启动，需要先启动eggroll和mysql再启动fateflow，fateflow依赖eggroll的启动。

2) 启动/关闭/重启fateboard服务

cd /data/projects/fate/fateboard
sh service.sh start|stop|status|restart
7.2 查看进程和端口
在目标服务器（192.168.65.161 192.168.65.162 ）app用户下执行

7.2.1 查看进程
#根据部署规划查看进程是否启动
ps -ef | grep -i clustermanager
ps -ef | grep -i nodemanager
ps -ef | grep -i rollsite
ps -ef | grep -i fate_flow_server.py
ps -ef | grep -i fateboard
7.2.2 查看进程端口
#根据部署规划查看进程端口是否存在
#clustermanager
netstat -tlnp | grep 4670
#nodemanager
netstat -tlnp | grep 4671
#rollsite
netstat -tlnp | grep 9370
#fate_flow_server
netstat -tlnp | grep 9360
#fateboard
netstat -tlnp | grep 8080

7.3 服务日志
服务	日志路径
eggroll	/data/projects/fate/eggroll/logs
fate_flow&任务日志	/data/projects/fate/python/logs
fateboard	/data/projects/fate/fateboard/logs
mysql	/data/logs/mysql/
8. 附录
完整的教程可以参考我的博客：https://blog.csdn.net/hhhhhhhhhhwwwwwwwwww/article/details/118894462?spm=1001.2014.3001.5502
